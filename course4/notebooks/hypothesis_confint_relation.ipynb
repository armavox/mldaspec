{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Качество классификатора\n",
    "---\n",
    "Пусть бинарный классификатор правильно предсказывает метку класса на 60 из 100 объектах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1_preds = np.concatenate((np.ones(60), np.zeros(40)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(clf1_preds.mean())\n",
    "print(len(clf1_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли считать, что он лучше чем генератор случайных чисел, который будет угадывать правильный ответ на сбалансированной выборке с вероятностью p=0.5?\n",
    "\n",
    "Для проверки построим доверительный интервал для доли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5039817664728937, 0.6960182335271062)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_confint(clf1_preds.sum(), len(clf1_preds), alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "В общем случае, если проверяется точечная нулевая гипотеза против двусторонней альтернативы: $$\\displaystyle H_0 : \\theta = \\theta_0, \\quad H_1: \\theta \\ne \\theta_0$$ то производить эту проверку можно путём построения доверительного интервала, как было показано выше. Нулевая гипотеза отвергается на уровне значимости α, если доверительный интервал для $\\theta$ с уровнем доверия 1−α не содержит $\\theta_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05688793364098078"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.binom_test(clf1_preds.sum(), len(clf1_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5020025867910618, 0.6905987135675411)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_confint(clf1_preds.sum(), len(clf1_preds), alpha=0.05, method='wilson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Пусть теперь помимо описанного ранее бинарного классификатора имеется второй классификатор, который на той же самой тестовой выборке верно предсказывает метки для 75 объектов из 100. Требуется определить, какой из двух классификаторов лучше. С одной стороны, 75 больше, чем 60. Но с другой стороны, выборка из 100 объектов не очень большая, и такая разница может возникнуть и случайно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2_preds = np.concatenate((np.ones(75), np.zeros(25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5020025867910618, 0.6905987135675411) (0.656955364519384, 0.8245478863771232)\n"
     ]
    }
   ],
   "source": [
    "clf1_confint = proportion_confint(clf1_preds.sum(), len(clf1_preds), method='wilson')\n",
    "clf2_confint = proportion_confint(clf2_preds.sum(), len(clf2_preds), method='wilson')\n",
    "print(clf1_confint, clf2_confint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_confint_diff_ind(sample1, sample2, alpha = 0.05):    \n",
    "    import scipy\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)   \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)\n",
    "\n",
    "def proportions_confint_diff_rel(sample1, sample2, alpha = 0.05):\n",
    "    import scipy\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    sample = list(zip(sample1, sample2))\n",
    "    n = len(sample)\n",
    "        \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    left_boundary = float(f - g) / n  - z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    right_boundary = float(f - g) / n  + z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учесть влияние случайности можно с помощью построения доверительных интервалов. Для первого клас- сификатора доверительный интервал Уилсона для доли верных предсказаний: [0.502,0.691]. Для второго классификатора такой же доверительный интервал: [0.657,0.825]. Эти доверительные интервалы пересека- ются по отрезку [0.657, 0.691]. Но пересечение доверительных интервалов не означает, что классификаторы нельзя различить по качеству. В данном случае выдвинута точечная нулевая гипотеза относительно двух параметров, θ1 и θ2, и необходимо проверить её против двусторонней альтернативы: $$H_0:\\theta_1 = \\theta_2, \\quad H_1:\\theta_1 \\ne \\theta_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правильным решением будет построить доверительный интервал для разности параметров θ1 и θ2, именно она полностью соответствует выдвинутой нулевой гипотезе (если θ1 = θ2, значит, их разность равна нулю). 95% доверительный интервал для разности долей в данной задаче: [0.022, 0.278]. Этот доверительный интервал не содержит ноль, значит, можно утверждать, что второй классификатор значимо лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.021850725876158883, 0.27814927412384116)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_confint_diff_ind(clf2_preds, clf1_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confusion_m.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Ранее не было учтено, что качество классификаторов определяется на одной и той же обучающей выборке, а значит, выборки в этой задаче — связанные. В такой ситуации доверительный интервал правильнее строить другим методом. \n",
    "\n",
    "Для этого используется таблица сопряжённости 3.3, и учитывается не количество ошибок каждого классификатора отдельно, а количество объектов, на которых классификаторы дали разные ответы (20 и 5 в этой таблице). \n",
    "\n",
    "Полученный 95% доверительный интервал для разности долей в связанных выборках равен [0.06, 0.243]. Обратите внимание, что этот доверительный интервал уже, и его левая граница дальше отстоит от нуля, то есть, при учёте связанности увеличивается уверенность в том, что классификаторы отличаются. Для данного интервала достигаемый уровень значимости p = 0.002. Он почти в десять раз меньше, чем при построении доверительного интервала без учёта связанности выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08001528740942768, 0.2199847125905723)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_confint_diff_rel(clf2_preds, clf1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 [mldaspec]",
   "language": "python",
   "name": "mldaspec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
