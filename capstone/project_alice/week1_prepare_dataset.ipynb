{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "Автор материала: программист-исследователь Mail.Ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ  [Юрий Кашницкий](https://yorko.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Capstone проект №1 <br> Идентификация пользователей по посещенным веб-страницам\n",
    "\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "В этом проекте мы будем решать задачу идентификации пользователя по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера, компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в [статье](https://habrahabr.ru/company/yandex/blog/230583/) на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам \"Traversal Pattern Mining\" и \"Sequential Pattern Mining\".\n",
    "\n",
    "\n",
    "Мы будем решать похожую задачу: по последовательности из нескольких веб-сайтов, посещенных подряд один и тем же человеком, мы будем идентифицировать этого человека. Идея такая: пользователи Интернета по-разному переходят по ссылкам, и это может помогать их идентифицировать (кто-то сначала в почту, потом про футбол почитать, затем новости, контакт, потом наконец – работать, кто-то – сразу работать).\n",
    "\n",
    "Будем использовать данные из [статьи](http://ceur-ws.org/Vol-1703/paper12.pdf) \"A Tool for Classification of Sequential Data\". И хотя мы не можем рекомендовать эту статью (описанные методы делеки от state-of-the-art, лучше обращаться к [книге](http://www.charuaggarwal.net/freqbook.pdf) \"Frequent Pattern Mining\" и последним статьям с ICDM), но данные там собраны аккуратно и представляют интерес.\n",
    "\n",
    "Имеются данные с прокси-серверов Университета Блеза Паскаля, они имеют очень простой вид. Для каждого пользователя заведен csv-файл с названием user\\*\\*\\*\\*.csv (где вместо звездочек – 4 цифры, соответствующие ID пользователя), а в нем посещения сайтов записаны в следующем формате: <br>\n",
    "\n",
    "<center>*timestamp, посещенный веб-сайт*</center>\n",
    "\n",
    "Скачать исходные данные можно по ссылке в статье, там же описание.\n",
    "Для этого задания хватит данных не по всем 3000 пользователям, а по 10 и 150. [Ссылка](https://drive.google.com/file/d/1AU3M_mFPofbfhFQa_Bktozq_vFREkWJA/view?usp=sharing) на архив *capstone_user_identification* (~7 Mb, в развернутом виде ~ 60 Mb). \n",
    "\n",
    "В финальном проекте уже придется столкнуться с тем, что не все операции можно выполнить за разумное время (скажем, перебрать с кросс-валидацией 100 комбинаций параметров случайного леса на этих данных Вы вряд ли сможете), поэтому мы будем использовать параллельно 2 выборки: по 10 пользователям и по 150. Для 10 пользователей будем писать и отлаживать код, для 150 – будет рабочая версия. \n",
    "\n",
    "Данные устроены следующем образом:\n",
    "\n",
    " - В каталоге 10users лежат 10 csv-файлов с названием вида \"user[USER_ID].csv\", где [USER_ID] – ID пользователя;\n",
    " - Аналогично для каталога 150users – там 150 файлов;\n",
    " - В каталоге 3users – игрушечный пример из 3 файлов, это для отладки кода предобработки, который Вы далее напишете.\n",
    "\n",
    "На 5 неделе будет задание по [соревнованию](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) Kaggle Inclass, которое организовано специально под Capstone проект нашей специализации. Соревнование уже открыто и, конечно, желающие могут начать уже сейчас.\n",
    "\n",
    "# <center>Неделя 1. Подготовка данных к анализу и построению моделей\n",
    "\n",
    "Первая часть проекта посвящена подготовке данных для дальнейшего описательного анализа и построения прогнозных моделей. Надо будет написать код для предобработки данных (исходно посещенные веб-сайты указаны для каждого пользователя в отдельном файле) и формирования единой обучающей выборки. Также в этой части мы познакомимся с разреженным форматом данных (матрицы `Scipy.sparse`), который хорошо подходит для данной задачи. \n",
    "\n",
    "**План 1 недели:**\n",
    " - Часть 1. Подготовка обучающей выборки\n",
    " - Часть 2. Работа с разреженным форматом данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "1. Заполните код в этой тетрадке \n",
    "2. Если вы проходите специализацию Яндеса и МФТИ, пошлите файл с ответами в соответствующем Programming Assignment. <br> Если вы проходите курс ODS, выберите ответы в [веб-форме](https://docs.google.com/forms/d/e/1FAIpQLSedmwHb4cOI32zKJmEP7RvgEjNoz5GbeYRc83qFXVH82KFgGA/viewform). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций 1 и 2 недели курса \"Математика и Python для анализа данных\":**\n",
    "   - [Циклы, функции, генераторы, list comprehension](https://www.coursera.org/learn/mathematics-and-python/lecture/Kd7dL/tsikly-funktsii-ghienieratory-list-comprehension)\n",
    "   - [Чтение данных из файлов](https://www.coursera.org/learn/mathematics-and-python/lecture/8Xvwp/chtieniie-dannykh-iz-failov)\n",
    "   - [Запись файлов, изменение файлов](https://www.coursera.org/learn/mathematics-and-python/lecture/vde7k/zapis-failov-izmienieniie-failov)\n",
    "   - [Pandas.DataFrame](https://www.coursera.org/learn/mathematics-and-python/lecture/rcjAW/pandas-data-frame)\n",
    "   - [Pandas. Индексация и селекция](https://www.coursera.org/learn/mathematics-and-python/lecture/lsXAR/pandas-indieksatsiia-i-sieliektsiia)\n",
    "   \n",
    "**Кроме того, в задании будут использоваться библиотеки Python [`glob`](https://docs.python.org/3/library/glob.html), [`pickle`](https://docs.python.org/2/library/pickle.html) и класс [`csr_matrix`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.html) из `Scipy.sparse`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, для лучшей воспроизводимости результатов приведем список версий основных используемых в проекте библиотек: NumPy, SciPy, Pandas, Matplotlib, Statsmodels и Scikit-learn. Для этого воспользуемся расширением [watermark](https://github.com/rasbt/watermark). Рекомендуется использовать докер-контейнер открытого курса OpenDataScience по машинному обучению, инструкции [тут](https://goo.gl/RrwpNd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.4\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.11.3\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "statsmodels 0.8.0\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 16.7.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : cb98f694ffbe8daae7bd8ace0fcca1899c5607fb\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "#pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на один из файлов с данными о посещенных пользователем (номер 31) веб-страницах.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "PATH_TO_DATA = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user31_data = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       '10users/user0031.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-15 08:12:07</td>\n",
       "      <td>fpdownload2.macromedia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15 08:12:18</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-11-15 08:12:07  fpdownload2.macromedia.com\n",
       "1  2013-11-15 08:12:17                 laposte.net\n",
       "2  2013-11-15 08:12:17             www.laposte.net\n",
       "3  2013-11-15 08:12:17              www.google.com\n",
       "4  2013-11-15 08:12:18             www.laposte.net"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user31_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поставим задачу классификации: идентифицировать пользователя по сессии из 10 подряд посещенных сайтов. Объектом в этой задаче будет сессия из 10 сайтов, последовательно посещенных одним и тем же пользователем, признаками – индексы этих 10 сайтов (чуть позже здесь появится \"мешок\" сайтов, подход Bag of Words). Целевым классом будет id пользователя.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Пример для иллюстрации</center>\n",
    "**Пусть пользователя всего 2, длина сессии – 2 сайта.**\n",
    "\n",
    "<center>user0001.csv</center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:01</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">00:00:11</td>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:16</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:20</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<center>user0002.csv</center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:02</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">00:00:14</td>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:17</td>\n",
    "    <td class=\"tg-031e\">facebook.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:25</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Идем по 1 файлу, нумеруем сайты подряд: vk.com – 1, google.com – 2 и т.д. Далее по второму файлу. \n",
    "\n",
    "Отображение сайтов в их индесы должно получиться таким:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "    <th class=\"tg-yw4l\">site_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">vk.com</td>\n",
    "    <td class=\"tg-yw4l\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "    <td class=\"tg-yw4l\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">yandex.ru</td>\n",
    "    <td class=\"tg-yw4l\">3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">facebook.com</td>\n",
    "    <td class=\"tg-yw4l\">4</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Тогда обучающая выборка будет такой (целевой признак – user_id):\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">session_id</th>\n",
    "    <th class=\"tg-hgcj\">site1</th>\n",
    "    <th class=\"tg-hgcj\">site2</th>\n",
    "    <th class=\"tg-amwm\">user_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">4</td>\n",
    "    <td class=\"tg-s6z2\">4</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Здесь 1 объект – это сессия из 2 посещенных сайтов 1-ым пользователем (target=1). Это сайты vk.com и google.com (номер 1 и 2). И так далее, всего 4 сессии. Пока сессии у нас не пересекаются по сайтам, то есть посещение каждого отдельного сайта относится только к одной сессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Подготовка обучающей выборки\n",
    "Реализуйте функцию *prepare_train_set*, которая принимает на вход путь к каталогу с csv-файлами *path_to_csv_files* и параметр *session_length* – длину сессии, а возвращает 2 объекта:\n",
    "- DataFrame, в котором строки соответствуют уникальным сессиям из *session_length* сайтов, *session_length* столбцов – индексам этих *session_length* сайтов и последний столбец – ID пользователя\n",
    "- частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n",
    "\n",
    "Детали:\n",
    "- Смотрите чуть ниже пример вывода, что должна возвращать функция\n",
    "- Используйте `glob` (или аналоги) для обхода файлов в каталоге. Для определенности, отсортируйте список файлов лексикографически. Удобно использовать `tqdm_notebook` (или просто `tqdm` в случае python-скрипта) для отслеживания числа выполненных итераций цикла\n",
    "- Создайте частотный словарь уникальных сайтов (вида {'site_string': (site_id, site_freq)}) и заполняйте его по ходу чтения файлов. Начните с 1\n",
    "- Рекомендуется меньшие индексы давать более часто попадающимся сайтам (приницип наименьшего описания)\n",
    "- Не делайте entity recognition, считайте *google.com*, *http://www.google.com* и *www.google.com* разными сайтами (подключить entity recognition можно уже в рамках индивидуальной работы над проектом)\n",
    "- Скорее всего в файле число записей не кратно числу *session_length*. Тогда последняя сессия будет короче. Остаток заполняйте нулями. То есть если в файле 24 записи и сессии длины 10, то 3 сессия будет состоять из 4 сайтов, и ей мы сопоставим вектор [*site1_id*, *site2_id*, *site3_id*, *site4_id*, 0, 0, 0, 0, 0, 0, *user_id*] \n",
    "- В итоге некоторые сессии могут повторяться – оставьте как есть, не удаляйте дубликаты. Если в двух сессиях все сайты одинаковы, но сессии принадлежат разным пользователям, то тоже оставляйте как есть, это естественная неопределенность в данных\n",
    "- Не оставляйте в частотном словаре сайт 0 (уже в конце, когда функция возвращает этот словарь)\n",
    "- 150 файлов из *capstone_websites_data/150users/* у меня обработались за 1.7 секунды, но многое, конечно, зависит от реализации функции и от используемого железа. И вообще, первая реализация скорее всего будет не самой эффективной, дальше можно заняться профилированием (особенно если планируете запускать этот код для 3000 пользователей). Также эффективная реализация этой функции поможет нам на следующей неделе."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# toy_df.site_id.shape \n",
    "# Out[]: 7600\n",
    "# 7600 / 7 ==  1085.714\n",
    "# 7600%7 == 5\n",
    "# (7600 + (7 - 7600 % 7)) / 7 == 1086.0\n",
    "# Number of elements to fill with zeros to make reshape possible is:\n",
    "# (7 - 7600 % 7) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/3users/user0001.csv',\n",
       " 'data/3users/user0002.csv',\n",
       " 'data/3users/user0003.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('data/3users'+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sites_dict(path_to_data, sites_dict=r'sites_dict.pkl',\n",
    "                       inds_dict=r'ind_to_sites_dict.pkl', refresh=False):\n",
    "    \"\"\"Func to get dictionaries for converting site's name to it's index.\n",
    "        If dictionary for data in PATH_TO_DATA has already been compiled, \n",
    "        functions just pickle dict out of files.\n",
    "    \"\"\"\n",
    "    def get_dict():\n",
    "        full_df = pd.DataFrame(columns=['timestamp', 'site'])\n",
    "        for file in tqdm(glob(path_to_data + '/*'), desc='Preparing sites dict...'):\n",
    "            temp_df = pd.read_csv(file, parse_dates=['timestamp'])\n",
    "            full_df = full_df.append(temp_df, ignore_index=True)\n",
    "\n",
    "        sites_freq_list = sorted(Counter(full_df.site).items(), \n",
    "                                 key=lambda x: x[1], reverse=True)\n",
    "        sites_dict = dict((s, [i, freq]) for i, (s, freq) in enumerate(sites_freq_list, 1))\n",
    "        ind_to_sites_dict = dict((val[0], key) for key, val in sites_dict.items())\n",
    "        ind_to_sites_dict[0] = 'no_site'\n",
    "        \n",
    "        # Save dict to file\n",
    "        with open('sites_dict.pkl', 'wb') as fout:\n",
    "            pickle.dump(sites_dict, fout)\n",
    "\n",
    "        with open('ind_to_sites_dict.pkl', 'wb') as fout:\n",
    "            pickle.dump(ind_to_sites_dict, fout)\n",
    "            \n",
    "        return sites_dict, ind_to_sites_dict\n",
    "    \n",
    "    try:\n",
    "        with open(sites_dict, 'rb') as input_file:\n",
    "            sites_dict = pickle.load(input_file)\n",
    "            \n",
    "        with open(inds_dict, 'rb') as input_file:\n",
    "            ind_to_sites_dict = pickle.load(input_file)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        sites_dict, ind_to_sites_dict = get_dict()\n",
    "#         full_df = pd.DataFrame(columns=['timestamp', 'site'])\n",
    "#         for file in tqdm(glob(PATH_TO_DATA + '/**/*'), desc='Preparing sites dict...'):\n",
    "#             temp_df = pd.read_csv(file, parse_dates=['timestamp'])\n",
    "#             full_df = full_df.append(temp_df, ignore_index=True)\n",
    "\n",
    "#         sites_freq_list = sorted(Counter(full_df.site).items(), \n",
    "#                                  key=lambda x: x[1], reverse=True)\n",
    "#         sites_dict = dict((s, [i, freq]) for i, (s, freq) in enumerate(sites_freq_list, 1))\n",
    "#         ind_to_sites_dict = dict((val[0], key) for key, val in sites_dict.items())\n",
    "#         ind_to_sites_dict[0] = 'no_site'\n",
    "\n",
    "#         # Save dict to file\n",
    "#         with open('sites_dict.pkl', 'wb') as fout:\n",
    "#             pickle.dump(sites_dict, fout)\n",
    "\n",
    "#         with open('ind_to_sites_dict.pkl', 'wb') as fout:\n",
    "#             pickle.dump(ind_to_sites_dict, fout)\n",
    "        \n",
    "    if refresh:\n",
    "        sites_dict, ind_to_sites_dict = get_dict()\n",
    "        \n",
    "    return sites_dict, ind_to_sites_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def prepare_train_set(path_to_csv_files, session_length=10, refresh_dict=False):\n",
    "    \"\"\"Func for partition users logs to desireable num of sessions\n",
    "        and prepare training dataset with sessions of particular users.\n",
    "    \"\"\"\n",
    "    \n",
    "    full_df = pd.DataFrame()\n",
    "    \n",
    "    sites_dict, inds_dict = prepare_sites_dict(path_to_csv_files, refresh=refresh_dict)\n",
    "        \n",
    "    for file in tqdm(glob(path_to_csv_files +'/*'), desc='Preparing training set...'):\n",
    "        temp_df = pd.read_csv(file, parse_dates=['timestamp'])\n",
    "        temp_df['site_id'] = temp_df.site.apply(lambda x: sites_dict[x][0])\n",
    "        \n",
    "        # Partition user data to sessions\n",
    "        try:\n",
    "            session = temp_df.site_id.values\n",
    "            session = session.reshape(-1, session_length)\n",
    "        except ValueError:\n",
    "            # We fill noncomplete array with zeros.\n",
    "            fill_with_zeros = session_length - temp_df.site_id.values.shape[0] % session_length\n",
    "            session = np.append(temp_df.site_id.values, [0]*fill_with_zeros)\n",
    "            session = session.reshape(-1, session_length)\n",
    "        \n",
    "        # Construct the full dataset, consist of user id's and sessions\n",
    "        temp_df = pd.DataFrame(session,\n",
    "                       columns=['site'+ str(x+1) for x in range(session_length)])\n",
    "        \n",
    "        user_id = re.findall(r'\\d+', file)[-1]\n",
    "        temp_df['user_id'] = [int(user_id)] * temp_df.shape[0]\n",
    "        \n",
    "        full_df = full_df.append(temp_df, ignore_index=True)\n",
    "    \n",
    "    return full_df, sites_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing sites dict...: 100%|██████████| 10/10 [00:00<00:00, 52.53it/s]\n",
      "Preparing training set...: 100%|██████████| 10/10 [00:00<00:00, 40.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 425 ms, sys: 46.1 ms, total: 471 ms\n",
      "Wall time: 468 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = PATH_TO_DATA + '/10users/'\n",
    "sessions_df, _ = prepare_train_set(path, refresh_dict=True)\n",
    "sessions_df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>574</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>203</td>\n",
       "      <td>133</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415</td>\n",
       "      <td>193</td>\n",
       "      <td>674</td>\n",
       "      <td>254</td>\n",
       "      <td>133</td>\n",
       "      <td>31</td>\n",
       "      <td>393</td>\n",
       "      <td>3305</td>\n",
       "      <td>217</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>293</td>\n",
       "      <td>415</td>\n",
       "      <td>333</td>\n",
       "      <td>897</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>473</td>\n",
       "      <td>3306</td>\n",
       "      <td>473</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>937</td>\n",
       "      <td>199</td>\n",
       "      <td>123</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>3307</td>\n",
       "      <td>258</td>\n",
       "      <td>211</td>\n",
       "      <td>3308</td>\n",
       "      <td>2086</td>\n",
       "      <td>675</td>\n",
       "      <td>2086</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226</td>\n",
       "      <td>675</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>128</td>\n",
       "      <td>172</td>\n",
       "      <td>3309</td>\n",
       "      <td>3310</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>350</td>\n",
       "      <td>574</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>31</td>\n",
       "      <td>133</td>\n",
       "      <td>393</td>\n",
       "      <td>192</td>\n",
       "      <td>133</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>262</td>\n",
       "      <td>3311</td>\n",
       "      <td>1550</td>\n",
       "      <td>393</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>199</td>\n",
       "      <td>123</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>333</td>\n",
       "      <td>106</td>\n",
       "      <td>203</td>\n",
       "      <td>1243</td>\n",
       "      <td>513</td>\n",
       "      <td>55</td>\n",
       "      <td>809</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1007</td>\n",
       "      <td>350</td>\n",
       "      <td>3312</td>\n",
       "      <td>350</td>\n",
       "      <td>3313</td>\n",
       "      <td>534</td>\n",
       "      <td>601</td>\n",
       "      <td>601</td>\n",
       "      <td>534</td>\n",
       "      <td>602</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>602</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>463</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2575</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2575</td>\n",
       "      <td>3314</td>\n",
       "      <td>3315</td>\n",
       "      <td>2087</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>108</td>\n",
       "      <td>561</td>\n",
       "      <td>603</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>108</td>\n",
       "      <td>384</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "      <td>2088</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90</td>\n",
       "      <td>733</td>\n",
       "      <td>5</td>\n",
       "      <td>101</td>\n",
       "      <td>22</td>\n",
       "      <td>1244</td>\n",
       "      <td>1244</td>\n",
       "      <td>90</td>\n",
       "      <td>561</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>142</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>142</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>366</td>\n",
       "      <td>310</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>310</td>\n",
       "      <td>366</td>\n",
       "      <td>310</td>\n",
       "      <td>1072</td>\n",
       "      <td>366</td>\n",
       "      <td>1373</td>\n",
       "      <td>1373</td>\n",
       "      <td>1072</td>\n",
       "      <td>310</td>\n",
       "      <td>366</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>310</td>\n",
       "      <td>366</td>\n",
       "      <td>2576</td>\n",
       "      <td>310</td>\n",
       "      <td>1245</td>\n",
       "      <td>1152</td>\n",
       "      <td>1245</td>\n",
       "      <td>310</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2576</td>\n",
       "      <td>1152</td>\n",
       "      <td>1245</td>\n",
       "      <td>1245</td>\n",
       "      <td>310</td>\n",
       "      <td>366</td>\n",
       "      <td>310</td>\n",
       "      <td>366</td>\n",
       "      <td>1152</td>\n",
       "      <td>310</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>366</td>\n",
       "      <td>366</td>\n",
       "      <td>1373</td>\n",
       "      <td>3</td>\n",
       "      <td>310</td>\n",
       "      <td>366</td>\n",
       "      <td>2</td>\n",
       "      <td>1373</td>\n",
       "      <td>464</td>\n",
       "      <td>1779</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>366</td>\n",
       "      <td>310</td>\n",
       "      <td>3</td>\n",
       "      <td>851</td>\n",
       "      <td>310</td>\n",
       "      <td>2</td>\n",
       "      <td>464</td>\n",
       "      <td>575</td>\n",
       "      <td>851</td>\n",
       "      <td>366</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>310</td>\n",
       "      <td>851</td>\n",
       "      <td>310</td>\n",
       "      <td>575</td>\n",
       "      <td>1072</td>\n",
       "      <td>366</td>\n",
       "      <td>851</td>\n",
       "      <td>310</td>\n",
       "      <td>575</td>\n",
       "      <td>1780</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2089</td>\n",
       "      <td>366</td>\n",
       "      <td>310</td>\n",
       "      <td>464</td>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "      <td>310</td>\n",
       "      <td>464</td>\n",
       "      <td>575</td>\n",
       "      <td>464</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>575</td>\n",
       "      <td>310</td>\n",
       "      <td>575</td>\n",
       "      <td>2090</td>\n",
       "      <td>810</td>\n",
       "      <td>575</td>\n",
       "      <td>310</td>\n",
       "      <td>575</td>\n",
       "      <td>851</td>\n",
       "      <td>464</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>575</td>\n",
       "      <td>366</td>\n",
       "      <td>310</td>\n",
       "      <td>464</td>\n",
       "      <td>575</td>\n",
       "      <td>464</td>\n",
       "      <td>310</td>\n",
       "      <td>464</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>851</td>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>193</td>\n",
       "      <td>464</td>\n",
       "      <td>674</td>\n",
       "      <td>464</td>\n",
       "      <td>342</td>\n",
       "      <td>128</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>575</td>\n",
       "      <td>464</td>\n",
       "      <td>293</td>\n",
       "      <td>575</td>\n",
       "      <td>1374</td>\n",
       "      <td>43</td>\n",
       "      <td>463</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1781</td>\n",
       "      <td>245</td>\n",
       "      <td>1781</td>\n",
       "      <td>588</td>\n",
       "      <td>1782</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>128</td>\n",
       "      <td>203</td>\n",
       "      <td>1374</td>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>588</td>\n",
       "      <td>1781</td>\n",
       "      <td>513</td>\n",
       "      <td>1551</td>\n",
       "      <td>588</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>67</td>\n",
       "      <td>577</td>\n",
       "      <td>67</td>\n",
       "      <td>537</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>85</td>\n",
       "      <td>52</td>\n",
       "      <td>242</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>254</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>112</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>138</td>\n",
       "      <td>15</td>\n",
       "      <td>266</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14034</th>\n",
       "      <td>454</td>\n",
       "      <td>454</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>218</td>\n",
       "      <td>421</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>454</td>\n",
       "      <td>37</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14035</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>463</td>\n",
       "      <td>72</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14036</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>527</td>\n",
       "      <td>527</td>\n",
       "      <td>527</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1455</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>1455</td>\n",
       "      <td>58</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14038</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>1455</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14039</th>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>107</td>\n",
       "      <td>92</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14040</th>\n",
       "      <td>36</td>\n",
       "      <td>107</td>\n",
       "      <td>73</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>36</td>\n",
       "      <td>246</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14041</th>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>212</td>\n",
       "      <td>654</td>\n",
       "      <td>2</td>\n",
       "      <td>746</td>\n",
       "      <td>457</td>\n",
       "      <td>479</td>\n",
       "      <td>175</td>\n",
       "      <td>31</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14042</th>\n",
       "      <td>251</td>\n",
       "      <td>524</td>\n",
       "      <td>283</td>\n",
       "      <td>175</td>\n",
       "      <td>246</td>\n",
       "      <td>80</td>\n",
       "      <td>283</td>\n",
       "      <td>52</td>\n",
       "      <td>297</td>\n",
       "      <td>283</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14043</th>\n",
       "      <td>172</td>\n",
       "      <td>369</td>\n",
       "      <td>20</td>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>4913</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14044</th>\n",
       "      <td>1625</td>\n",
       "      <td>1625</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1625</td>\n",
       "      <td>18</td>\n",
       "      <td>1625</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14045</th>\n",
       "      <td>2245</td>\n",
       "      <td>19</td>\n",
       "      <td>85</td>\n",
       "      <td>498</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14046</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>161</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14047</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>138</td>\n",
       "      <td>112</td>\n",
       "      <td>266</td>\n",
       "      <td>454</td>\n",
       "      <td>67</td>\n",
       "      <td>218</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14048</th>\n",
       "      <td>421</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14050</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14051</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14053</th>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14054</th>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14055</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>463</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14056</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>65</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14057</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>65</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14058</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14059</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14060</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14061 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       site1  site2  site3  site4  site5  site6  site7  site8  site9  site10  \\\n",
       "0        192    574    133      3    133    133      3    133    203     133   \n",
       "1        415    193    674    254    133     31    393   3305    217      55   \n",
       "2         55      3     55     55      5    293    415    333    897      55   \n",
       "3        473   3306    473     55     55     55     55    937    199     123   \n",
       "4        342     55      5   3307    258    211   3308   2086    675    2086   \n",
       "5        226    675    211    211     55     55    128    172   3309    3310   \n",
       "6        350    574    133      3    133     31    133    393    192     133   \n",
       "7        262   3311   1550    393     55      3     55      3    199     123   \n",
       "8         55    333    106    203   1243    513     55    809    106       5   \n",
       "9       1007    350   3312    350   3313    534    601    601    534     602   \n",
       "10       602    172    172    463      2      2      6      3      2    2575   \n",
       "11      2575   3314   3315   2087    160    160    117     90      2      90   \n",
       "12       108    561    603     18     44    108    384     17     90    2088   \n",
       "13        90    733      5    101     22   1244   1244     90    561      31   \n",
       "14        20     31     20     90      5    117      6      3      2       2   \n",
       "15        54      2     62     86     54     86     62     54     62     142   \n",
       "16        54     62     54    142     61     61     61     61    366     310   \n",
       "17       310    366    310   1072    366   1373   1373   1072    310     366   \n",
       "18        98     98    310    366   2576    310   1245   1152   1245     310   \n",
       "19      2576   1152   1245   1245    310    366    310    366   1152     310   \n",
       "20       366    366   1373      3    310    366      2   1373    464    1779   \n",
       "21       366    310      3    851    310      2    464    575    851     366   \n",
       "22       310    851    310    575   1072    366    851    310    575    1780   \n",
       "23      2089    366    310    464    851    851    310    464    575     464   \n",
       "24       575    310    575   2090    810    575    310    575    851     464   \n",
       "25       575    366    310    464    575    464    310    464    575     575   \n",
       "26       851    464    464    464    193    464    674    464    342     128   \n",
       "27       464    464    464    575    464    293    575   1374     43     463   \n",
       "28         2      2      3      6      2   1781    245   1781    588    1782   \n",
       "29       128    203   1374    212      5    588   1781    513   1551     588   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "14031     67    577     67    537     37     24     24     85     52     242   \n",
       "14032    242    242     37     24     24    254     24     37     37      24   \n",
       "14033     37     24     24     37    112     72     15    138     15     266   \n",
       "14034    454    454     67     52    218    421     24     37    454      37   \n",
       "14035     24     24     37     24     37     24     15      2    463      72   \n",
       "14036     15      2    527    527    527      2     58     58     31       3   \n",
       "14037     58     31      2   1455      3     58    136      3   1455      58   \n",
       "14038     58      3      5     15     58      2     18     17     36    1455   \n",
       "14039     22     44      5     15      3     36    107     92     36       3   \n",
       "14040     36    107     73     15     36    157     36    246     36      36   \n",
       "14041    259      5    212    654      2    746    457    479    175      31   \n",
       "14042    251    524    283    175    246     80    283     52    297     283   \n",
       "14043    172    369     20    119      3      2      6     10    105    4913   \n",
       "14044   1625   1625     44     17      5   1625     18   1625   1008    1008   \n",
       "14045   2245     19     85    498    285    285     24     37     37      24   \n",
       "14046     69     69    161     24     37     72     15      2      2      15   \n",
       "14047     15     15     15     15    138    112    266    454     67     218   \n",
       "14048    421    218      2     65     21     27      6     10      3      30   \n",
       "14049      9     33     37     24     51      9      6     23      4      88   \n",
       "14050      9      2     37     24      2      2     64     64     64      64   \n",
       "14051     64     64     64     64     64     64     64     64     64      64   \n",
       "14052     64     64      2      9      9     24     37      9      9       9   \n",
       "14053     24     37      9      9      9      9     24     37      9       9   \n",
       "14054     24     37      9      9     60     60     60     60     39      39   \n",
       "14055     93      2    463      2     93     93     93      2      2       2   \n",
       "14056      3      4      6     10      2     21      3      6     27      65   \n",
       "14057     10     21     65     27     30      3      4      9      4      30   \n",
       "14058     33      4      9      6     10     51      9     33      4       4   \n",
       "14059      4      4      4     43     51      4      3      3      9       4   \n",
       "14060     10     21      0      0      0      0      0      0      0       0   \n",
       "\n",
       "       user_id  \n",
       "0           31  \n",
       "1           31  \n",
       "2           31  \n",
       "3           31  \n",
       "4           31  \n",
       "5           31  \n",
       "6           31  \n",
       "7           31  \n",
       "8           31  \n",
       "9           31  \n",
       "10          31  \n",
       "11          31  \n",
       "12          31  \n",
       "13          31  \n",
       "14          31  \n",
       "15          31  \n",
       "16          31  \n",
       "17          31  \n",
       "18          31  \n",
       "19          31  \n",
       "20          31  \n",
       "21          31  \n",
       "22          31  \n",
       "23          31  \n",
       "24          31  \n",
       "25          31  \n",
       "26          31  \n",
       "27          31  \n",
       "28          31  \n",
       "29          31  \n",
       "...        ...  \n",
       "14031      241  \n",
       "14032      241  \n",
       "14033      241  \n",
       "14034      241  \n",
       "14035      241  \n",
       "14036      241  \n",
       "14037      241  \n",
       "14038      241  \n",
       "14039      241  \n",
       "14040      241  \n",
       "14041      241  \n",
       "14042      241  \n",
       "14043      241  \n",
       "14044      241  \n",
       "14045      241  \n",
       "14046      241  \n",
       "14047      241  \n",
       "14048      241  \n",
       "14049      241  \n",
       "14050      241  \n",
       "14051      241  \n",
       "14052      241  \n",
       "14053      241  \n",
       "14054      241  \n",
       "14055      241  \n",
       "14056      241  \n",
       "14057      241  \n",
       "14058      241  \n",
       "14059      241  \n",
       "14060      241  \n",
       "\n",
       "[14061 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "toy_df = pd.read_csv('data/10users/user0031.csv', parse_dates=['timestamp'])\n",
    "flat = toy_df.sort_values(by='site').head(10)['site'].values.flatten()\n",
    "flat\n",
    "\n",
    "\n",
    "data = [1] * flat.shape[0]\n",
    "indices = [sites_dict[x][0] for x in flat]\n",
    "indptr = range(0, flat.shape[0] + 1, 3)\n",
    "\n",
    "csr_matrix((data, indices, indptr))[:, 1:].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените полученную функцию к игрушечному примеру, убедитесь, что все работает как надо.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing sites dict...: 100%|██████████| 3/3 [00:00<00:00, 588.59it/s]\n",
      "Preparing sites dict...: 100%|██████████| 3/3 [00:00<00:00, 434.21it/s]\n",
      "Preparing training set...: 100%|██████████| 3/3 [00:00<00:00, 396.51it/s]\n"
     ]
    }
   ],
   "source": [
    "_, inds_dict = prepare_sites_dict('data/3users', refresh=True)\n",
    "toy_df, _ = prepare_train_set('data/3users', refresh_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>geo.mozilla.org</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>accounts.google.com</td>\n",
       "      <td>mail.google.com</td>\n",
       "      <td>apis.google.com</td>\n",
       "      <td>plus.google.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>football.kulichki.ru</td>\n",
       "      <td>football.kulichki.ru</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meduza.io</td>\n",
       "      <td>google.com</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>mail.google.com</td>\n",
       "      <td>yandex.ru</td>\n",
       "      <td>meduza.io</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meduza.io</td>\n",
       "      <td>google.com</td>\n",
       "      <td>oracle.com</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>no_site</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       site1       site2                 site3                 site4  \\\n",
       "0     vk.com  oracle.com            oracle.com       geo.mozilla.org   \n",
       "1     vk.com  google.com            google.com            google.com   \n",
       "2     vk.com  oracle.com  football.kulichki.ru  football.kulichki.ru   \n",
       "3  meduza.io  google.com            oracle.com            google.com   \n",
       "4  meduza.io  google.com            oracle.com               no_site   \n",
       "\n",
       "        site5       site6                site7            site8  \\\n",
       "0  oracle.com  google.com  accounts.google.com  mail.google.com   \n",
       "1     no_site     no_site              no_site          no_site   \n",
       "2  oracle.com     no_site              no_site          no_site   \n",
       "3  oracle.com  google.com           google.com  mail.google.com   \n",
       "4     no_site     no_site              no_site          no_site   \n",
       "\n",
       "             site9           site10  user_id  \n",
       "0  apis.google.com  plus.google.com        1  \n",
       "1          no_site          no_site        1  \n",
       "2          no_site          no_site        2  \n",
       "3        yandex.ru        meduza.io        3  \n",
       "4          no_site          no_site        3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df[list(set(toy_df.columns) - set(['user_id']))] = toy_df[list(set(toy_df.columns) - set(['user_id']))].applymap(lambda x: inds_dict[x])\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\r\n",
      "2013-11-15 09:28:17,vk.com\r\n",
      "2013-11-15 09:33:04,oracle.com\r\n",
      "2013-11-15 09:52:48,oracle.com\r\n",
      "2013-11-15 11:37:26,geo.mozilla.org\r\n",
      "2013-11-15 11:40:32,oracle.com\r\n",
      "2013-11-15 11:40:34,google.com\r\n",
      "2013-11-15 11:40:35,accounts.google.com\r\n",
      "2013-11-15 11:40:37,mail.google.com\r\n",
      "2013-11-15 11:40:40,apis.google.com\r\n",
      "2013-11-15 11:41:35,plus.google.com\r\n",
      "2013-11-15 12:40:35,vk.com\r\n",
      "2013-11-15 12:40:37,google.com\r\n",
      "2013-11-15 12:40:40,google.com\r\n",
      "2013-11-15 12:41:35,google.com\r\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0001.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\r\n",
      "2013-11-15 09:28:17,vk.com\r\n",
      "2013-11-15 09:33:04,oracle.com\r\n",
      "2013-11-15 09:52:48,football.kulichki.ru\r\n",
      "2013-11-15 11:37:26,football.kulichki.ru\r\n",
      "2013-11-15 11:40:32,oracle.com\r\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0002.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\r\n",
      "2013-11-15 09:28:17,meduza.io\r\n",
      "2013-11-15 09:33:04,google.com\r\n",
      "2013-11-15 09:52:48,oracle.com\r\n",
      "2013-11-15 11:37:26,google.com\r\n",
      "2013-11-15 11:40:32,oracle.com\r\n",
      "2013-11-15 11:40:34,google.com\r\n",
      "2013-11-15 11:40:35,google.com\r\n",
      "2013-11-15 11:40:37,mail.google.com\r\n",
      "2013-11-15 11:40:40,yandex.ru\r\n",
      "2013-11-15 11:41:35,meduza.io\r\n",
      "2013-11-15 12:28:17,meduza.io\r\n",
      "2013-11-15 12:33:04,google.com\r\n",
      "2013-11-15 12:52:48,oracle.com\r\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0003.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing sites dict...: 100%|██████████| 3/3 [00:00<00:00, 394.39it/s]\n",
      "Preparing training set...: 100%|██████████| 3/3 [00:00<00:00, 348.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_toy, site_freq_3users = prepare_train_set(os.path.join(PATH_TO_DATA, '3users'), \n",
    "                                                     session_length=10, refresh_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site1  site2  site3  site4  site5  site6  site7  site8  site9  site10  \\\n",
       "0      3      2      2      7      2      1      8      5      9      10   \n",
       "1      3      1      1      1      0      0      0      0      0       0   \n",
       "2      3      2      6      6      2      0      0      0      0       0   \n",
       "3      4      1      2      1      2      1      1      5     11       4   \n",
       "4      4      1      2      0      0      0      0      0      0       0   \n",
       "\n",
       "   user_id  \n",
       "0        1  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частоты сайтов (второй элемент кортежа) точно должны быть такими, нумерация может быть любой (первые элементы кортежей могут отличаться)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accounts.google.com': [8, 1],\n",
       " 'apis.google.com': [9, 1],\n",
       " 'football.kulichki.ru': [6, 2],\n",
       " 'geo.mozilla.org': [7, 1],\n",
       " 'google.com': [1, 9],\n",
       " 'mail.google.com': [5, 2],\n",
       " 'meduza.io': [4, 3],\n",
       " 'oracle.com': [2, 8],\n",
       " 'plus.google.com': [10, 1],\n",
       " 'vk.com': [3, 3],\n",
       " 'yandex.ru': [11, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_freq_3users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените полученную функцию к данным по 10 пользователям.\n",
    "\n",
    "**<font color='red'> Вопрос 1. </font> Сколько уникальных сессий из 10 сайтов в выборке с 10 пользователями?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing sites dict...: 100%|██████████| 10/10 [00:00<00:00, 58.32it/s]\n",
      "Preparing training set...: 100%|██████████| 10/10 [00:00<00:00, 46.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14061, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_10users, site_freq_10users = prepare_train_set('data/10users/', refresh_dict=True)\n",
    "train_data_10users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 2. </font> Сколько всего уникальных сайтов в выборке из 10 пользователей? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_freq_10users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените полученную функцию к данным по 150 пользователям.\n",
    "\n",
    "**<font color='red'> Вопрос 3. </font> Сколько уникальных сессий из 10 сайтов в выборке с 150 пользователями?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing sites dict...: 100%|██████████| 150/150 [00:03<00:00, 28.64it/s]\n",
      "Preparing training set...: 100%|██████████| 150/150 [00:03<00:00, 47.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.6 s, sys: 1.73 s, total: 7.33 s\n",
      "Wall time: 7.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data_150users, site_freq_150users = prepare_train_set('data/150users/',\n",
    "                                                            refresh_dict=True)\n",
    "train_data_150users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137019"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_150users.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 4. </font> Сколько всего уникальных сайтов в выборке из 150 пользователей? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27797"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_freq_150users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 5. </font> Какой из этих сайтов НЕ входит в топ-10 самых популярных сайтов среди посещенных 150 пользователями?**\n",
    "- www.google.fr\n",
    "- www.youtube.com\n",
    "- safebrowsing-cache.google.com\n",
    "- www.linkedin.com **[+]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.google.fr',\n",
       " 'www.google.com',\n",
       " 'www.facebook.com',\n",
       " 'apis.google.com',\n",
       " 's.youtube.com',\n",
       " 'clients1.google.com',\n",
       " 'mail.google.com',\n",
       " 'plus.google.com',\n",
       " 'safebrowsing-cache.google.com',\n",
       " 'www.youtube.com']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(site_freq_150users)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для дальнейшего анализа запишем полученные объекты DataFrame в csv-файлы.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_10users.to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       'train_data_10users.csv'), \n",
    "                        index_label='session_id', float_format='%d')\n",
    "train_data_150users.to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                        'train_data_150users.csv'), \n",
    "                         index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Работа с разреженным форматом данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если так подумать, то полученные признаки *site1*, ..., *site10* смысла не имеют как признаки в задаче классификации. А вот если воспользоваться идеей мешка слов из анализа текстов – это другое дело. Создадим новые матрицы, в которых строкам будут соответствовать сессии из 10 сайтов, а столбцам – индексы сайтов. На пересечении строки $i$ и столбца $j$ будет стоять число $n_{ij}$ – cколько раз сайт $j$ встретился в сессии номер $i$. Делать это будем с помощью разреженных матриц Scipy – [csr_matrix](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.html). Прочитайте документацию, разберитесь, как использовать разреженные матрицы и создайте такие матрицы для наших данных. Сначала проверьте на игрушечном примере, затем примените для 10 и 150 пользователей. \n",
    "\n",
    "Обратите внимание, что в коротких сессиях, меньше 10 сайтов, у нас остались нули, так что первый признак (сколько раз попался 0) по смыслу отличен от остальных (сколько раз попался сайт с индексом $i$). Поэтому первый столбец разреженной матрицы надо будет удалить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_toy, y_toy = train_data_toy.iloc[:, :-1].values, train_data_toy.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  2,  2, 10,  2,  1,  7,  5,  8,  9],\n",
       "       [ 3,  1,  1,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  2,  6,  6,  2,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  2,  1,  2,  1,  1,  5, 11,  4],\n",
       "       [ 4,  1,  2,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sparse_toy = csr_matrix ''' ВАШ КОД ЗДЕСЬ '''   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Размерность разреженной матрицы должна получиться равной 11, поскольку в игрушечном примере 3 пользователя посетили 11 уникальных сайтов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 3, 1, 0, 1, 0, 1, 1, 1, 1, 0],\n",
       "        [3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "        [4, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse_toy.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_10users, y_10users = train_data_10users.iloc[:, :-1].values, \\\n",
    "                       train_data_10users.iloc[:, -1].values\n",
    "X_150users, y_150users = train_data_150users.iloc[:, :-1].values, \\\n",
    "                         train_data_150users.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sparse_10users = ''' ВАШ КОД ЗДЕСЬ '''\n",
    "X_sparse_150users = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохраним эти разреженные матрицы с помощью [pickle](https://docs.python.org/2/library/pickle.html) (сериализация в Python), также сохраним вектора *y_10users, y_150users* – целевые значения (id пользователя)  в выборках из 10 и 150 пользователей. То что названия этих матриц начинаются с X и y, намекает на то, что на этих данных мы будем проверять первые модели классификации.\n",
    "Наконец, сохраним также и частотные словари сайтов для 3, 10 и 150 пользователей.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, 'X_sparse_10users.pkl'), 'wb') as X10_pkl:\n",
    "    pickle.dump(X_sparse_10users, X10_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'y_10users.pkl'), 'wb') as y10_pkl:\n",
    "    pickle.dump(y_10users, y10_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'X_sparse_150users.pkl'), 'wb') as X150_pkl:\n",
    "    pickle.dump(X_sparse_150users, X150_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'y_150users.pkl'), 'wb') as y150_pkl:\n",
    "    pickle.dump(y_150users, y150_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_3users.pkl'), 'wb') as site_freq_3users_pkl:\n",
    "    pickle.dump(site_freq_3users, site_freq_3users_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_10users.pkl'), 'wb') as site_freq_10users_pkl:\n",
    "    pickle.dump(site_freq_10users, site_freq_10users_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_150users.pkl'), 'wb') as site_freq_150users_pkl:\n",
    "    pickle.dump(site_freq_150users, site_freq_150users_pkl, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чисто для подстраховки проверим, что число столбцов в разреженных матрицах `X_sparse_10users` и `X_sparse_150users` равно ранее посчитанным числам уникальных сайтов для 10 и 150 пользователей соответственно.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_sparse_10users.shape[1] == len(site_freq_10users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_sparse_150users.shape[1] == len(site_freq_150users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пути улучшения\n",
    "-  можно обработать исходные данные по 3000 пользователей; обучать на такой выборке модели лучше при наличии доступа к хорошим мощностям (можно арендовать инстанс Amazon EC2, как именно, описано [тут](https://habrahabr.ru/post/280562/)). Хотя далее в курсе мы познакомимся с алгоритмами, способными обучаться на больших выборках при малых вычислительных потребностях;\n",
    "- помимо явного создания разреженного формата можно еще составить выборки с помощью `CountVectorizer`, `TfidfVectorizer` и т.п. Поскольку данные по сути могут быть описаны как последовательности, то можно вычислять n-граммы сайтов. Работает все это или нет, мы будем проверять в [соревновании](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) Kaggle Inclass (желающие могут начать уже сейчас).\n",
    "\n",
    "На следующей неделе мы еще немного поготовим данные и потестируем первые гипотезы, связанные с нашими наблюдениями. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6.4 [capstone]",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
